{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VideoSummarization-PresentationNotebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKjAtW2x+D5niPaS84wtkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cshivak/AllureRepo/blob/master/VideoSummarization_PresentationNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxUGJAZ5BNo6",
        "colab_type": "text"
      },
      "source": [
        "Reference:\n",
        "https://towardsdatascience.com/object-detection-and-tracking-in-pytorch-b3cf1a696a98"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvHXr1vsBMW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbCVJcf4BNI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/cfotache/pytorch_objectdetecttrack.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR15WbytB2Mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ffmpeg-python\n",
        "!pip install filterpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdYtRCD8B2Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/pytorch_objectdetecttrack')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyGkn5LOB2Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models import *\n",
        "from utils import *\n",
        "import ffmpeg\n",
        "\n",
        "import os, sys, time, datetime, random\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import imutils\n",
        "import cv2\n",
        "from IPython.display import clear_output\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import math\n",
        "import shutil\n",
        "import progressbar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnYR_08zB2Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Background subtraction option1\n",
        "### Color images with subtraction written as a video\n",
        "input_video = '/content/1.mp4'\n",
        "output_video = '/content/video_bs.mp4'\n",
        "probe = ffmpeg.probe(input_video)\n",
        "video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
        "duration = int(math.ceil(float(video_stream['duration'])))\n",
        "width = int(video_stream['width'])\n",
        "height = int(video_stream['height'])\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
        "video=cv2.VideoWriter(output_video, fourcc,10,(width,height))\n",
        "\n",
        "cap = cv2.VideoCapture(input_video)\n",
        "# fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "fgbg = cv2.createBackgroundSubtractorKNN()\n",
        "\n",
        "try:\n",
        "  while(1):\n",
        "      ret, frame = cap.read()\n",
        "\n",
        "      fgmask = fgbg.apply(frame)\n",
        "      mask_rgb = cv2.cvtColor(fgmask, cv2.COLOR_GRAY2RGB)\n",
        "      out_frame = cv2.bitwise_and(frame, mask_rgb)\n",
        "      video.write(out_frame)\n",
        "      k = cv2.waitKey(30)\n",
        "      if k == 27:\n",
        "          break\n",
        "\n",
        "  cap.release()\n",
        "  video.release()\n",
        "  cv2.destroyAllWindows()\n",
        "except:\n",
        "  cap.release()\n",
        "  video.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7PU0dD1B2XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Background subtraction option-2\n",
        "# inputVideo = '/content/1.mp4'\n",
        "# output_video = '/content/video_bs.mp4'\n",
        "# cap = cv2.VideoCapture(inputVideo)\n",
        "# probe = ffmpeg.probe(inputVideo)\n",
        "# video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
        "# duration = int(math.ceil(float(video_stream['duration'])))\n",
        "# width = int(video_stream['width'])\n",
        "# height = int(video_stream['height'])\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
        "# video=cv2.VideoWriter(output_video, fourcc,10,(width,height))\n",
        "# #fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "# fgbg = cv2.createBackgroundSubtractorKNN(detectShadows = False)\n",
        "# kernel = np.ones((2,2),np.uint8)\n",
        "# i = 0\n",
        "# try:\n",
        "#   while True:\n",
        "#       ret, frame = cap.read()\n",
        "#       # cv2_imshow('orginal',frame)\n",
        "#       frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "#       frame_hsv[:, :, 2] = cv2.equalizeHist(frame_hsv[:, :, 2])\n",
        "#       frame = cv2.cvtColor(frame_hsv, cv2.COLOR_HSV2BGR)\n",
        "#       fgmask = fgbg.apply(frame)\n",
        "#       fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
        "#       fgmask = cv2.blur(fgmask,(3,3))\n",
        "#       # cv2.imshow(\"Frame\",fgmask)\n",
        "#       red_frame = cv2.bitwise_and(frame[:,:,2], fgmask)\n",
        "#       green_frame = cv2.bitwise_and(frame[:,:,1], fgmask)\n",
        "#       blue_frame = cv2.bitwise_and(frame[:,:,0], fgmask)\n",
        "#       # cv2_imshow(cv2.merge((blue_frame,green_frame,red_frame)))\n",
        "#       video.write(cv2.merge((blue_frame,green_frame,red_frame)))\n",
        "#       clear_output(wait=True)\n",
        "#       k = cv2.waitKey(30)\n",
        "#       if k == 27:\n",
        "#           break\n",
        "#   cv2.destroyAllWindows()\n",
        "#   cap.release()\n",
        "#   video.release()\n",
        "# except:\n",
        "#   cv2.destroyAllWindows()\n",
        "#   cap.release()\n",
        "#   video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS13lzLCB2Zw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### YOLO needs this. May go away if different implementation is used\n",
        "config_path='/content/pytorch_objectdetecttrack/config/yolov3.cfg'\n",
        "weights_path='/content/yolov3.weights'\n",
        "class_path='/content/pytorch_objectdetecttrack/config/coco.names'\n",
        "img_size=416\n",
        "conf_thres=0.8\n",
        "nms_thres=0.4\n",
        "# Load model and weights\n",
        "model = Darknet(config_path, img_size=img_size)\n",
        "model.load_weights(weights_path)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "classes = utils.load_classes(class_path)\n",
        "Tensor = torch.cuda.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SQuob-WB2cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_image(img):\n",
        "    # scale and pad image\n",
        "    ratio = min(img_size/img.size[0], img_size/img.size[1])\n",
        "    imw = round(img.size[0] * ratio)\n",
        "    imh = round(img.size[1] * ratio)\n",
        "    img_transforms=transforms.Compose([transforms.Resize((imh,imw)),\n",
        "         transforms.Pad((max(int((imh-imw)/2),0), \n",
        "              max(int((imw-imh)/2),0), max(int((imh-imw)/2),0),\n",
        "              max(int((imw-imh)/2),0)), (128,128,128)),\n",
        "         transforms.ToTensor(),\n",
        "         ])\n",
        "    # convert image to Tensor\n",
        "    image_tensor = img_transforms(img).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input_img = Variable(image_tensor.type(Tensor))\n",
        "    # run inference on the model and get detections\n",
        "    with torch.no_grad():\n",
        "        detections = model(input_img)\n",
        "        detections = utils.non_max_suppression(detections, 80, \n",
        "                        conf_thres, nms_thres)\n",
        "    return detections[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8QTxslhB2e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### May go away if different implementation is used completely or partially\n",
        "## Use background subtracted video as input and write frames\n",
        "videopath = os.path.join(os.getcwd(), 'video_bs.mp4')\n",
        "cmap = plt.get_cmap('tab20b')\n",
        "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
        "# initialize Sort object and video capture\n",
        "from sort import *\n",
        "vid = cv2.VideoCapture(videopath)\n",
        "mot_tracker = Sort()\n",
        "# dict = defaultdict(list) \n",
        "# objectBBox = defaultdict(list) \n",
        "summaryDf = pd.DataFrame(columns=['objectId', 'frame', 'x', 'y', 'x+w', 'y+w'])\n",
        "\n",
        "probe = ffmpeg.probe(videopath)\n",
        "video_stream = next((stream for stream in probe['streams'] if stream['codec_type'] == 'video'), None)\n",
        "duration = int(math.ceil(float(video_stream['duration'])))\n",
        "width = int(video_stream['width'])\n",
        "height = int(video_stream['height'])\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
        "# video=cv2.VideoWriter(os.path.join(os.getcwd(), 'video.mp4'),fourcc,10,(width,height))\n",
        "if os.path.exists('/content/Images'):\n",
        "  shutil.rmtree('/content/Images')\n",
        "  os.mkdir('/content/Images')\n",
        "else: \n",
        "  os.mkdir('/content/Images')\n",
        "#while(True):\n",
        "for ii in range(duration):\n",
        "    ret, frame = vid.read()\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    pilimg = Image.fromarray(frame)\n",
        "    detections = detect_image(pilimg)\n",
        "    img = np.array(pilimg)\n",
        "    pad_x = max(img.shape[0] - img.shape[1], 0) * (img_size / max(img.shape))\n",
        "    pad_y = max(img.shape[1] - img.shape[0], 0) * (img_size / max(img.shape))\n",
        "    unpad_h = img_size - pad_y\n",
        "    unpad_w = img_size - pad_x\n",
        "    if detections is not None:\n",
        "        tracked_objects = mot_tracker.update(detections.cpu())\n",
        "        unique_labels = detections[:, -1].cpu().unique()\n",
        "        n_cls_preds = len(unique_labels)\n",
        "        for x1, y1, x2, y2, obj_id, cls_pred in tracked_objects:\n",
        "            box_h = int(((y2 - y1) / unpad_h) * img.shape[0])\n",
        "            box_w = int(((x2 - x1) / unpad_w) * img.shape[1])\n",
        "            y1 = int(((y1 - pad_y // 2) / unpad_h) * img.shape[0])\n",
        "            x1 = int(((x1 - pad_x // 2) / unpad_w) * img.shape[1])\n",
        "            color = colors[int(obj_id) % len(colors)]\n",
        "            color = [i * 255 for i in color]\n",
        "            cls = classes[int(cls_pred)]\n",
        "            # cv2.rectangle(frame, (x1, y1), (x1+box_w, y1+box_h),\n",
        "            #              color, 1)\n",
        "            # cv2.rectangle(frame, (x1, y1-35), (x1+len(cls)*19+60,\n",
        "            #              y1), color, -1)\n",
        "            # cv2.putText(frame, str(obj_id), \n",
        "            #             (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "            #             1, (255,255,255), 1)\n",
        "            data = [{'objectId':obj_id,'frame':ii,'x':x1,'y':y1,'x+w': x1+box_w, 'y+w': y1+box_h}]\n",
        "            summaryDf = summaryDf.append(data)\n",
        "            # dict[obj_id].append(ii)\n",
        "            # objectBBox[obj_id].append((x1, y1, x1+box_w, y1+box_h))\n",
        "            # print(obj_id, ii)\n",
        "    # fig=figure(figsize=(12, 8))\n",
        "    # title(\"Video Stream\")\n",
        "    # imshow(frame)\n",
        "    # show()\n",
        "    cv2.imwrite(os.path.join('/content/Images', '{0}.png'.format(ii)),frame)\n",
        "    # video.write(frame)\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "# file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBf9cwMZB2h4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### summaryDf now has info on which frame an object appears and it's coordinates\n",
        "summaryDf['frame'].sort_values().unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT4XLlEPB2mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summaryDf['objectId'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzsFKeF7B2o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summaryDf.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG7U1lCkB2ry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pasteImageBlackBg(s_img, x_offset, y_offset, imgId, frame):\n",
        "  # Use regex to get text\n",
        "  # text = imgPath.split('/')[-1].split('.p')[0]\n",
        "  # s_img = cv2.imread(imgPath, -1)\n",
        "  l_img = np.zeros((500,634,3), np.uint8)\n",
        "\n",
        "  y1, y2 = y_offset, y_offset + s_img.shape[0]\n",
        "  x1, x2 = x_offset, x_offset + s_img.shape[1]\n",
        "\n",
        "  alpha_s = s_img[:, :, 2] / 255.0\n",
        "  alpha_l = 1.0 - alpha_s\n",
        "\n",
        "  for c in range(0, 3):\n",
        "      l_img[y1:y2, x1:x2, c] = (alpha_s * s_img[:, :, c] +\n",
        "                                alpha_l * l_img[y1:y2, x1:x2, c])\n",
        "      \n",
        "  cv2.putText(l_img, '{0}-{1}'.format(imgId, frame), \n",
        "              (x_offset + 40, y_offset-10), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "              0.30, (255,255,255), 1)\n",
        "  return l_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC30aUKDB2uD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Crop images using bounding boxes and extract person based on objectId and paste on black background\n",
        "imagesPath = '/content/Images'\n",
        "cropImagePath = '/content/ImagesCropped'\n",
        "\n",
        "if os.path.exists(cropImagePath):\n",
        "  shutil.rmtree(cropImagePath)\n",
        "  os.mkdir(cropImagePath)\n",
        "else:\n",
        "  os.mkdir(cropImagePath)\n",
        "for object in list(summaryDf['objectId']):\n",
        "  for frame in summaryDf[summaryDf['objectId'] == object]['frame']:\n",
        "    if(frame > 10):\n",
        "      row = summaryDf[(summaryDf['objectId'] == object) & (summaryDf['frame'] == frame)]\n",
        "      x = int(row['x'])\n",
        "      y = int(row['y'])\n",
        "      yw = int(row['y+w'])\n",
        "      xw = int(row['x+w'])\n",
        "      img = cv2.imread(os.path.join(imagesPath, '{0}.png'.format(frame)))\n",
        "      cropImg = img[y:yw, x:xw]\n",
        "      pastImg = pasteImageBlackBg(cropImg, x, y, object, frame)\n",
        "      cv2.imwrite(os.path.join(cropImagePath, '{0}_{1}.png'.format(object, frame)),pastImg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrzlzAIbB2wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Frames under 30 are just blank. Maynot need this. Investigate??\n",
        "summaryDf = summaryDf[summaryDf['frame'] > 39]\n",
        "summaryDf.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3rzUaOB2yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "croppedFolderPath = '/content/ImagesCropped'\n",
        "overLaidImagePath = '/content/OverlaidImages'\n",
        "output_video = '/content/final.mp4'\n",
        "if os.path.exists(overLaidImagePath):\n",
        "  shutil.rmtree(overLaidImagePath)\n",
        "  os.mkdir(overLaidImagePath)\n",
        "else:\n",
        "  os.mkdir(overLaidImagePath)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
        "video=cv2.VideoWriter(output_video, fourcc,10,(634,500))\n",
        "i = 0\n",
        "while summaryDf.shape[0]!= 0:\n",
        "  x = summaryDf.groupby(summaryDf['objectId']).first()\n",
        "  x['objectId'] = x.index\n",
        "  x['fileNames'] = x.apply(lambda row: '{0}_{1}.png'.format(row['objectId'], int(row['frame'])), axis=1)\n",
        "  l_img = np.zeros((500,634,3), np.uint8)\n",
        "  for fileName in list(x['fileNames']):\n",
        "    # print(os.path.join(croppedFolderPath ,fileName))\n",
        "    img = cv2.imread(os.path.join(croppedFolderPath ,fileName))\n",
        "    # cv2_imshow(img)\n",
        "    l_img = cv2.addWeighted(l_img,1.0,img,2.0,0)\n",
        "  # cv2_imshow(l_img)\n",
        "  cv2.imwrite(os.path.join(overLaidImagePath, '{0}.png'.format(i)),l_img)\n",
        "  video.write(l_img)\n",
        "  x.drop(['fileNames'], axis = 1, inplace = True )\n",
        "  summaryDf = pd.concat([summaryDf, x])\n",
        "  summaryDf = summaryDf.drop_duplicates(keep=False)\n",
        "  i += 1\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2B8vUeAB21X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_video = '/content/final.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
        "video=cv2.VideoWriter(output_video, fourcc,10,(634,500))\n",
        "for i in range(0, 57):\n",
        "  img = cv2.imread(os.path.join(overLaidImagePath, '{0}.png'.format(str(i))))\n",
        "  # print(os.path.join(overLaidImagePath, '{0}.png'.format(str(i))))\n",
        "  # cv2_imshow(img)\n",
        "  video.write(img)\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5fifAOoB23s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UJv0h5CB26O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKl2Cex8B287",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBpCU1WzB2_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAg_zfvfB3Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1WLTjTIB3Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZAXOoRwB3JE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQEncqOVB3Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCidxc0GB3Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bipX-BDHB3C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3IHPpZzB2k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}